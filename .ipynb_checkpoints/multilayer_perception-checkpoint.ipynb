{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93178e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load multilayer_perception.py\n",
    "#\n",
    "\n",
    "import torch\n",
    "from d2l import torch as d2l\n",
    "import gydl\n",
    "\n",
    "\n",
    "\n",
    "def center_control() :\n",
    "    x = torch.arange(-8.0 , 8.0 , 0.1 , requires_grad=True)\n",
    "    y = torch.relu(x)\n",
    "    d2l.plot( x.detach().numpy() , y.detach() , 'x' , 'relu(x)' , figsize=(5,2.5))\n",
    "    y.backward(torch.ones_like(x),retain_graph=True)\n",
    "    d2l.plot(x.detach() , x.grad , 'x' , 'grade of relu' , figsize=(5,2.5))\n",
    "    #d2l.plt.show()\n",
    "\n",
    "    \n",
    "batch_size=256\n",
    "train_iter , test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "num_inputs , num_outputs , num_hiddens = 784,10,256\n",
    "num_epochs , lr = 10 , 0.1\n",
    "# one lay percepter ,# 784 to 256 for what\n",
    "W1 = torch.nn.Parameter(torch.randn(num_inputs,num_hiddens,requires_grad=True)*0.01)\n",
    "B1 = torch.nn.Parameter(torch.zeros(num_hiddens, requires_grad=True ))\n",
    "W2 = torch.nn.Parameter(torch.randn(num_hiddens , num_outputs , requires_grad=True)*0.01)\n",
    "B2 = torch.nn.Parameter(torch.zeros(num_outputs, requires_grad=True ))\n",
    "# linear\n",
    "W = torch.nn.Parameter(torch.randn(num_inputs,num_outputs,requires_grad=True)*0.01)\n",
    "B = torch.nn.Parameter(torch.zeros(num_outputs, requires_grad=True ))\n",
    "\n",
    "def _softmax(X) :\n",
    "    X_exp = torch.exp(X)\n",
    "    partition = X_exp.sum( 1 , keepdim = True )\n",
    "    return X_exp / partition\n",
    "def linear_net(X) :   \n",
    "    return _softmax(torch.matmul(X.reshape((-1,W.shape[0])) , W) + b )\n",
    "    # adjust X to 256 * 728 Matrix for Maxtrix multiply with W  \n",
    "\n",
    "def linear() :\n",
    "    \"\"\" \"\"\"\n",
    "    params = [W,B]\n",
    "    loss = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    updater = torch.optim.SGD(params , lr = lr )\n",
    "    gydl.Train(perceper_net,train_iter , test_iter,loss, num_epochs,updater).start()\n",
    "\n",
    "    \n",
    "def _relu(X) :\n",
    "    a = torch.zeros_like(X)\n",
    "    return torch.max(X,a)\n",
    "\n",
    "def perceper_net(X) :\n",
    "    \"\"\" one layer perceper\"\"\"\n",
    "    X = X.reshape((-1,W1.shape[0]))\n",
    "    H = _relu(X@W1+B1)\n",
    "    return (H@W2+B2)\n",
    "\n",
    "def onelayer_perceper() :\n",
    "    \"\"\" \"\"\"\n",
    "    params = [W1 , B1 , W2 , B2]\n",
    "    loss = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    updater = torch.optim.SGD(params , lr = lr )\n",
    "    gydl.Train(perceper_net,train_iter , test_iter,loss, num_epochs,updater).start()\n",
    "    \n",
    "        \n",
    "def center_control_2() :\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\" :\n",
    "    print(\"ss\")\n",
    "    center_control_2() \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
