{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "529a7183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************\n"
     ]
    }
   ],
   "source": [
    "# %load linar_nerve_net_2.py\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch \n",
    "import torchvision\n",
    "#import d2l \n",
    "from d2l import torch as d2l \n",
    "from torch.utils import data \n",
    "from IPython import display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "class Accumulator :\n",
    "    \n",
    "    def __init__(self , n) :\n",
    "        self.data = [0.0] * n \n",
    "\n",
    "    def add(self , *args) :\n",
    "        self.data = [ a + float(b) for a , b in zip(self.data , args)]\n",
    "    \n",
    "    def reset(self) :\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self , indx) :\n",
    "        return self.data[indx]\n",
    "\n",
    "\n",
    "\n",
    "class Animator: \n",
    "    \n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "        ylim=None, xscale='linear', yscale='linear',\n",
    "            fmts=('r-', 'b--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                figsize=(3.5, 2.5)):\n",
    "        # 增量地绘制多条线\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        d2l.use_svg_display() #use svg pictrue format display \n",
    "        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "            # 使用lambda函数捕获参数\n",
    "        self.config_axes = lambda: d2l.set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def add(self , x , y) :\n",
    "        if not hasattr( y , \"__len__\") :\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x , \"__len__\") :\n",
    "            x = [x] * n \n",
    "        if not self.X :\n",
    "            self.X = [ [] for _ in range(n)]\n",
    "        if not self.Y :\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "\n",
    "\n",
    "def get_dataloader_workers() : \n",
    "    return 4 \n",
    "\n",
    "#********************************************************************\n",
    "#\n",
    "# download fasion dataset by MNIST and transfroming it  \n",
    "#\n",
    "#\n",
    "\n",
    "def loading_fasion_mnist_2(batch_size , resize = None ) :\n",
    "    \n",
    "    trans = [torchvision.transforms.ToTensor()]\n",
    "    if resize :\n",
    "        trans.insert( 0 , torchvision.transforms.Resize(resize))\n",
    "    trans = torchvision.transforms.Compose(trans) \n",
    "    mnist_train = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../data2\" , train=True , transform=trans , download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../data2\" , train=False , transform=trans , download=True)\n",
    "    return (data.DataLoader(mnist_train , batch_size , shuffle=True , \n",
    "        num_workers=get_dataloader_workers()) , \n",
    "            data.DataLoader(mnist_test , batch_size , shuffle = False ,\n",
    "                num_workers=get_dataloader_workers()))\n",
    "\n",
    "\n",
    "\n",
    "#********************************************************************\n",
    "#\n",
    "# download hand writing digit dataset by MNIST and transfroming it  \n",
    "#\n",
    "#\n",
    "def loading_digit_data_set(batch_size,train=True  ) :\n",
    "    assert isinstance(train,bool) \n",
    "    \n",
    "    data_set =torchvision.datasets.MNIST('./data' , train=train , download=False , \n",
    "        transform=torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize((0.1307,),(0.3071,)) \n",
    "    ]))\n",
    "    dataloader = torch.utils.data.DataLoader(data_set , \n",
    "        batch_size , shuffle=train)\n",
    "    \n",
    "    return dataloader \n",
    "\n",
    "\n",
    "\n",
    "#************************************************************************\n",
    "#\n",
    "#\n",
    "#\n",
    "def show_images( imgs , num_rows , num_cols , titles=None , scale=1.5) :\n",
    "    \"\"\" \"\"\"\n",
    "    figsize = (num_cols * scale , num_rows * scale ) \n",
    "    _ , axes = d2l.plt.subplots(num_rows , num_cols , figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i , (ax , img) in enumerate(zip(axes , imgs)) :\n",
    "        if torch.is_tensor(img) :\n",
    "            ax.imshow(img.numpy())\n",
    "        else :            \n",
    "            ax.imshow(img)\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "        if titles : \n",
    "            ax.set_title(titles[i])\n",
    "        \n",
    "    d2l.plt.show() #encapsulate show func\n",
    "    \n",
    "    return axes \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lr = 0.1    #learn rate\n",
    "\n",
    "num_inputs = 784    # features\n",
    "num_outputs = 10    # classic number \n",
    "\n",
    "W = torch.normal( 0 , 0.01 , size=(num_inputs , num_outputs) , requires_grad = True )\n",
    "# init Weigh arguments W with Gauss distribution N(0,0.01)\n",
    "\n",
    "b = torch.zeros( num_outputs , requires_grad = True )\n",
    "# init Bias with zero \n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "\n",
    "__recognize__ = 'digit'\n",
    "# digit or clothes classic init choose \n",
    "if __recognize__ == 'clothes' : \n",
    "    train_iter, test_iter = loading_fasion_mnist_2(batch_size)\n",
    "    def get_labels(labels) :\n",
    "        table_labels = ['tshirt' , 'trouser' , 'pullover' , 'dress' , 'coat',\n",
    "            'sandal' , 'shirt' , 'sneaker' , 'bag' , 'ankle boot']\n",
    "        return [ table_labels[int(i)] for i in labels]\n",
    "\n",
    "if __recognize__ == 'digit' :\n",
    "    train_iter = loading_digit_data_set(batch_size )\n",
    "    test_iter = loading_digit_data_set(batch_size , train=False)\n",
    "    # digit version     \n",
    "    def get_labels(labels) :\n",
    "        table_labels = ['0' , '1' , '2' , '3' , '4',\n",
    "            '5' , '6' , '7' , '8' , '9']\n",
    "        return [ table_labels[int(i)] for i in labels]\n",
    "\n",
    "def softmax(X) :\n",
    "    X_exp = torch.exp(X)\n",
    "    partition = X_exp.sum( 1 , keepdim = True )\n",
    "    return X_exp / partition\n",
    "\n",
    "def net(X) :   \n",
    "    return softmax( torch.matmul(X.reshape((-1,W.shape[0])) , W) + b )\n",
    "    # adjust X to 256 * 728 Matrix for Maxtrix multiply with W  \n",
    "def cross_entropy(y_hat , y) :\n",
    "    return - torch.log(y_hat[range(len(y_hat)) , y ])\n",
    "\n",
    "\n",
    "def accuracy( y_hat , y) :\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1 :\n",
    "        y_hat = y_hat.argmax(axis=1) # return index of argmax with axis = 1 \n",
    "    cmp = y_hat.type(y.dtype) == y \n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "\n",
    "def evaluate_accuracy(net , data_iter) :\n",
    "    if isinstance(net , torch.nn.Module) :\n",
    "        net.eval() # just evaluate not train\n",
    "    metric = Accumulator(2) \n",
    "    with torch.no_grad() :\n",
    "        for X , y in data_iter :\n",
    "            metric.add(accuracy(net(X) , y) , y.numel())\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "def sgd(params , batch_size) :\n",
    "    with torch.no_grad() :\n",
    "        for param in params :\n",
    "            #print(param.grad) \n",
    "            param -= lr * param.grad/batch_size\n",
    "            param.grad.zero_()\n",
    "\n",
    "def updater(batch_size) :\n",
    "    return sgd([W,b], batch_size)\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(net , train_iter , loss , updater) :\n",
    "    if isinstance(net , torch.nn.Module) :\n",
    "        net.train()\n",
    "    metric = Accumulator(3)\n",
    "    for X , y in train_iter : \n",
    "        y_hat = net(X)\n",
    "        #print(y_hat)\n",
    "        l = loss(y_hat , y)\n",
    "        #print(l)\n",
    "        if isinstance(updater , torch.optim.Optimizer) : \n",
    "            updater.zero_grad()\n",
    "            l.mean().backward()\n",
    "            updater.step()\n",
    "        else :\n",
    "            l.sum().backward()\n",
    "            updater(X.shape[0])\n",
    "        metric.add( float(l.sum()) , accuracy(y_hat , y) , y.numel())\n",
    "    return metric[0]/metric[2] , metric[1]/metric[2]\n",
    "\n",
    "\n",
    "\n",
    "def train(net, train_iter, test_iter, loss, num_epochs, updater): \n",
    "    \n",
    "    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],\n",
    "        legend=['train loss', 'train acc', 'test acc'])\n",
    "    for epoch in range(num_epochs):\n",
    "        print(epoch)\n",
    "        train_metrics = train_epoch(net , train_iter , loss, updater)\n",
    "        test_acc = evaluate_accuracy(net , test_iter)\n",
    "        animator.add(epoch + 1 , train_metrics + (test_acc,))\n",
    "    train_loss, train_acc = train_metrics\n",
    "    assert train_loss < 0.5, train_loss\n",
    "    assert train_acc <= 1 and train_acc > 0.7, train_acc\n",
    "    assert test_acc <= 1 and test_acc > 0.7, test_acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dominant_control_3() :\n",
    "    \n",
    "    #net = torch.nn.Sequential(torch.nn.Flatten() , torch.nn.Linear(784,10))\n",
    "    num_epochs = 10\n",
    "    train(net , train_iter , test_iter , cross_entropy , num_epochs , updater)\n",
    "    \n",
    "    for X , y in test_iter :\n",
    "        break\n",
    "    #trues = d2l.get_fashion_mnist_labels(y)\n",
    "    trues = get_labels(y)\n",
    "    #preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1))\n",
    "    preds = get_labels(net(X).argmax(axis=1))\n",
    "    titles = [true + '\\n' + pred for true , pred in zip(trues , preds )]\n",
    "    n = 6\n",
    "    d2l.show_images(X[0:n].reshape((n,28,28)) , 1 , n , titles=titles[0:n])\n",
    "    print(titles)\n",
    "\n",
    "\n",
    "\n",
    "def test() :\n",
    "    \"\"\"test detail \"\"\"\n",
    "    #X , y = next(iter(train_iter))\n",
    "    \n",
    "    #show_images(X.reshape(18,28,28) , 2 , 9 , titles=get_labels(y))\n",
    "\n",
    "    #num_epochs=10\n",
    "\n",
    "    #animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],\n",
    "    #    legend=['train loss', 'train acc', 'test acc'])\n",
    "    \n",
    "    #y = torch.tensor([[0,2],[0,1],[0,3]])\n",
    "    #print(len(y))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\" :\n",
    "    print('************************')\n",
    "    #dominant_control_3()\n",
    "    #pic_debug()\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72fb7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
